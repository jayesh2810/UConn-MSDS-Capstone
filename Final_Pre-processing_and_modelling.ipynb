{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total_impressions</th>\n",
       "      <th>total_clicks</th>\n",
       "      <th>total_apply_starts</th>\n",
       "      <th>actual_title</th>\n",
       "      <th>job_salary</th>\n",
       "      <th>cluster</th>\n",
       "      <th>job_state_freq</th>\n",
       "      <th>job_city_freq</th>\n",
       "      <th>advertiser_name_freq</th>\n",
       "      <th>employee_count_encoded</th>\n",
       "      <th>log_total_apply_starts</th>\n",
       "      <th>sqrt_total_apply_starts</th>\n",
       "      <th>boxcox_total_apply_starts</th>\n",
       "      <th>yeojohnson_total_apply_starts</th>\n",
       "      <th>click_imp_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3423260</th>\n",
       "      <td>28526427</td>\n",
       "      <td>283333</td>\n",
       "      <td>18682</td>\n",
       "      <td>3742</td>\n",
       "      <td>AI Content Writer</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072537</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>3.067247e-05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.227643</td>\n",
       "      <td>61.171889</td>\n",
       "      <td>1.963695</td>\n",
       "      <td>2.127554</td>\n",
       "      <td>0.065937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423261</th>\n",
       "      <td>28526750</td>\n",
       "      <td>340575</td>\n",
       "      <td>21237</td>\n",
       "      <td>4118</td>\n",
       "      <td>AI Content Writer</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026569</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>3.067247e-05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.323366</td>\n",
       "      <td>64.171645</td>\n",
       "      <td>1.965210</td>\n",
       "      <td>2.129968</td>\n",
       "      <td>0.062356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423262</th>\n",
       "      <td>38767878</td>\n",
       "      <td>418525</td>\n",
       "      <td>26086</td>\n",
       "      <td>8310</td>\n",
       "      <td>Customer Care Representative</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>5.842376e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.025335</td>\n",
       "      <td>91.159201</td>\n",
       "      <td>1.974356</td>\n",
       "      <td>2.144533</td>\n",
       "      <td>0.062328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423263</th>\n",
       "      <td>28526848</td>\n",
       "      <td>455158</td>\n",
       "      <td>28551</td>\n",
       "      <td>4818</td>\n",
       "      <td>AI Content Writer</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081970</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>3.067247e-05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.480322</td>\n",
       "      <td>69.411815</td>\n",
       "      <td>1.967543</td>\n",
       "      <td>2.133682</td>\n",
       "      <td>0.062728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423264</th>\n",
       "      <td>38273190</td>\n",
       "      <td>657552</td>\n",
       "      <td>40531</td>\n",
       "      <td>4127</td>\n",
       "      <td>Online ELA Tutor</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>2.921188e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.325548</td>\n",
       "      <td>64.241731</td>\n",
       "      <td>1.965244</td>\n",
       "      <td>2.130021</td>\n",
       "      <td>0.061639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  total_impressions  total_clicks  total_apply_starts  \\\n",
       "3423260  28526427             283333         18682                3742   \n",
       "3423261  28526750             340575         21237                4118   \n",
       "3423262  38767878             418525         26086                8310   \n",
       "3423263  28526848             455158         28551                4818   \n",
       "3423264  38273190             657552         40531                4127   \n",
       "\n",
       "                         actual_title  job_salary  cluster  job_state_freq  \\\n",
       "3423260             AI Content Writer     45000.0        0        0.072537   \n",
       "3423261             AI Content Writer     45000.0        0        0.026569   \n",
       "3423262  Customer Care Representative     24000.0        3        0.010666   \n",
       "3423263             AI Content Writer     45000.0        0        0.081970   \n",
       "3423264              Online ELA Tutor     44000.0        0        0.012086   \n",
       "\n",
       "         job_city_freq  advertiser_name_freq  employee_count_encoded  \\\n",
       "3423260       0.004428          3.067247e-05                     6.0   \n",
       "3423261       0.005121          3.067247e-05                     6.0   \n",
       "3423262       0.000099          5.842376e-07                     2.0   \n",
       "3423263       0.008609          3.067247e-05                     6.0   \n",
       "3423264       0.000478          2.921188e-07                     2.0   \n",
       "\n",
       "         log_total_apply_starts  sqrt_total_apply_starts  \\\n",
       "3423260                8.227643                61.171889   \n",
       "3423261                8.323366                64.171645   \n",
       "3423262                9.025335                91.159201   \n",
       "3423263                8.480322                69.411815   \n",
       "3423264                8.325548                64.241731   \n",
       "\n",
       "         boxcox_total_apply_starts  yeojohnson_total_apply_starts  \\\n",
       "3423260                   1.963695                       2.127554   \n",
       "3423261                   1.965210                       2.129968   \n",
       "3423262                   1.974356                       2.144533   \n",
       "3423263                   1.967543                       2.133682   \n",
       "3423264                   1.965244                       2.130021   \n",
       "\n",
       "         click_imp_ratio  \n",
       "3423260         0.065937  \n",
       "3423261         0.062356  \n",
       "3423262         0.062328  \n",
       "3423263         0.062728  \n",
       "3423264         0.061639  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data file and print the head of the data\n",
    "df = pd.read_csv('XYZ/DataWithClusterLabel.csv')\n",
    "# df = pd.read_csv('XYZ/Final_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_apply_starts'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the count of missing values in the data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing values in the columns 'job_state', 'job_city' and 'advertiser_name'\n",
    "df = df.dropna(subset=['job_state', 'job_city','advertiser_name'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 # Print the count of missing values in the data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the unique values in the column 'job_state'\n",
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map the clusters to new clusters \n",
    "def map_cluster(cluster):\n",
    "    if cluster in [1, 3, 5, 8, 9]:\n",
    "        return 6\n",
    "    elif cluster == 0:\n",
    "        return 0\n",
    "    elif cluster == 2:\n",
    "        return 1\n",
    "    elif cluster == 4:\n",
    "        return 2\n",
    "    elif cluster == 6:\n",
    "        return 3\n",
    "    elif cluster == 7:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['new_cluster'] = df['cluster'].apply(map_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the unique values in the column 'new_cluster'\n",
    "df['new_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing job salaries with the mean salary within each job_state and new_cluster group\n",
    "df['job_salary'] = df.groupby(['job_state', 'new_cluster'])['job_salary'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 # Print the count of missing values in the data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'employee_count' column with 'Unknown'\n",
    "df['employee_count'] = df['employee_count'].fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 # Print the count of missing values in the data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data\n",
    "df_og = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the unique number of values of 'advertiser_name'\n",
    "df['advertiser_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                     FREQUENCY ENCODING\n",
    "\n",
    "\n",
    "# Define a function to perform frequency encoding\n",
    "def frequency_encoding(column):\n",
    "    freq = df[column].value_counts() / len(df)\n",
    "    return df[column].map(freq)\n",
    "\n",
    "df['job_state_freq'] = frequency_encoding('job_state')\n",
    "df['job_city_freq'] = frequency_encoding('job_city')\n",
    "df['advertiser_name_freq'] = frequency_encoding('advertiser_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #                                     TARGET ENCODING\n",
    "\n",
    "# categorical_columns = ['job_state', 'job_city', 'advertiser_name']\n",
    "# target_column = 'total_impressions'\n",
    "\n",
    "# # Function to perform target encoding\n",
    "# def target_encode(df, categorical_columns, target_column):\n",
    "#     encoded_df = df.copy()\n",
    "#     for col in categorical_columns:\n",
    "#         # Calculate the mean of the target column for each category\n",
    "#         target_mean = df.groupby(col)[target_column].mean()\n",
    "#         # Map the mean values to the original dataframe\n",
    "#         encoded_df[col + '_encoded'] = df[col].map(target_mean)\n",
    "#     return encoded_df\n",
    "\n",
    "# # Perform target encoding\n",
    "# encoded_df = target_encode(df, categorical_columns, target_column)\n",
    "\n",
    "# # Display the encoded dataframe\n",
    "# encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Drop the columns 'job_state', 'job_city' and 'advertiser_name'\n",
    "df = df.drop(['job_state', 'job_city', 'advertiser_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print value_counts of 'employee_count'\n",
    "df['employee_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OrdinalEncoder class from sklearn\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Define the order of the categories\n",
    "employee_count_order = ['1-49', '50-149', '150-249', '250-499', '500-749', '750-999' ,'1000+', 'Unknown']\n",
    "\n",
    "# Create an instance of OrdinalEncoder with the specified order\n",
    "ordinal_encoder = OrdinalEncoder(categories=[employee_count_order])\n",
    "\n",
    "# Encode the 'employee_count' column\n",
    "df['employee_count_encoded'] = ordinal_encoder.fit_transform(df[['employee_count']])\n",
    "df = df.drop('employee_count', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Applying various transformations to the 'total_apply_starts' column\n",
    "df['log_total_apply_starts'] = np.log1p(df['total_apply_starts'])  # Using log1p to handle zeros\n",
    "df['sqrt_total_apply_starts'] = np.sqrt(df['total_apply_starts'])\n",
    "df['boxcox_total_apply_starts'], _ = stats.boxcox(df['total_apply_starts'] + 1)  # Adding 1 to handle zeros\n",
    "\n",
    "# Using Yeo-Johnson transformation which can handle zeros and negative values\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "df['yeojohnson_total_apply_starts'] = pt.fit_transform(df[['total_apply_starts']])\n",
    "\n",
    "# Display summary statistics for the original and transformed columns\n",
    "df[['total_apply_starts', 'log_total_apply_starts', 'sqrt_total_apply_starts', 'boxcox_total_apply_starts', 'yeojohnson_total_apply_starts']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'click_imp_ratio' by dividing 'total_clicks' by 'total_impressions'\n",
    "df['click_imp_ratio'] = df['total_clicks'] / df['total_impressions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.drop(['id','total_impressions','total_clicks','actual_title','sqrt_total_apply_starts','boxcox_total_apply_starts','yeojohnson_total_apply_starts'],axis=1).corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 id\n",
      "1 total_impressions\n",
      "2 total_clicks\n",
      "3 total_apply_starts\n",
      "4 actual_title\n",
      "5 job_salary\n",
      "6 cluster\n",
      "7 job_state_freq\n",
      "8 job_city_freq\n",
      "9 advertiser_name_freq\n",
      "10 employee_count_encoded\n",
      "11 log_total_apply_starts\n",
      "12 sqrt_total_apply_starts\n",
      "13 boxcox_total_apply_starts\n",
      "14 yeojohnson_total_apply_starts\n",
      "15 click_imp_ratio\n"
     ]
    }
   ],
   "source": [
    "# Enumerate the columns of the dataframe\n",
    "for i,j in enumerate(df.columns):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select features and target variable for the model\n",
    "X = df1.iloc[:, np.r_[5,6,7,8,9,10]]\n",
    "y = df1['log_total_apply_starts']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1028)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2666253, 6)\n",
      "(666564, 6)\n",
      "(2666253,)\n",
      "(666564,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the training and testing sets\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_salary</th>\n",
       "      <th>cluster</th>\n",
       "      <th>job_state_freq</th>\n",
       "      <th>job_city_freq</th>\n",
       "      <th>advertiser_name_freq</th>\n",
       "      <th>employee_count_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048606</th>\n",
       "      <td>62319.414712</td>\n",
       "      <td>7</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>8.763563e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838012</th>\n",
       "      <td>91750.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038558</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>2.670842e-03</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154038</th>\n",
       "      <td>78584.651070</td>\n",
       "      <td>9</td>\n",
       "      <td>0.026569</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>2.728389e-03</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168622</th>\n",
       "      <td>70720.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.089188e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134033</th>\n",
       "      <td>52000.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.081970</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>1.089188e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           job_salary  cluster  job_state_freq  job_city_freq  \\\n",
       "1048606  62319.414712        7        0.029213       0.003268   \n",
       "838012   91750.000000        2        0.038558       0.001720   \n",
       "154038   78584.651070        9        0.026569       0.005121   \n",
       "168622   70720.000000        8        0.034400       0.000010   \n",
       "134033   52000.000000        8        0.081970       0.001761   \n",
       "\n",
       "         advertiser_name_freq  employee_count_encoded  \n",
       "1048606          8.763563e-07                     0.0  \n",
       "838012           2.670842e-03                     3.0  \n",
       "154038           2.728389e-03                     7.0  \n",
       "168622           1.089188e-01                     1.0  \n",
       "134033           1.089188e-01                     1.0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to train and evaluate multiple regression models\n",
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(),\n",
    "        'Decision Tree': DecisionTreeRegressor()\n",
    "    }\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "     \n",
    "        print(f'{name} Model:')\n",
    "        print(f'Training R²: {train_r2:.4f}')\n",
    "        print(f'Training MSE: {train_mse:.4f}')\n",
    "        print(f'Testing R²: {test_r2:.4f}')\n",
    "        print(f'Testing MSE: {test_mse:.4f}')\n",
    "        print('-' * 30)\n",
    "\n",
    "# Train and evaluate models using the training and testing sets\n",
    "train_and_evaluate_models(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Function to train and evaluate multiple advanced regression models\n",
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        'Gradient Boosting': GradientBoostingRegressor(),\n",
    "        'AdaBoost': AdaBoostRegressor(),\n",
    "        'XGBoost': XGBRegressor(),\n",
    "        'LightGBM': LGBMRegressor()\n",
    "    }\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "     \n",
    "        print(f'{name} Model:')\n",
    "        print(f'Training R²: {train_r2:.4f}')\n",
    "        print(f'Training MSE: {train_mse:.4f}')\n",
    "        print(f'Testing R²: {test_r2:.4f}')\n",
    "        print(f'Testing MSE: {test_mse:.4f}')\n",
    "        print('-' * 30)\n",
    "\n",
    "# Train and evaluate models using the training and testing sets\n",
    "train_and_evaluate_models(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        'Gradient Boosting': GradientBoostingRegressor(),\n",
    "        'AdaBoost': AdaBoostRegressor(),\n",
    "        'XGBoost': XGBRegressor(),\n",
    "        'LightGBM': LGBMRegressor()\n",
    "    }\n",
    "\n",
    "    feature_names = X_train.columns if hasattr(X_train, 'columns') else [f'Feature {i}' for i in range(X_train.shape[1])]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        \n",
    "        print(f'{name} Model:')\n",
    "        print(f'Training R²: {train_r2:.4f}')\n",
    "        print(f'Training MSE: {train_mse:.4f}')\n",
    "        print(f'Testing R²: {test_r2:.4f}')\n",
    "        print(f'Testing MSE: {test_mse:.4f}')\n",
    "        print('\\n')\n",
    "\n",
    "        # Print sorted feature importance if available\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance = model.feature_importances_\n",
    "            sorted_indices = importance.argsort()[::-1]  # Get indices of features sorted by importance\n",
    "            print('Sorted Feature Importance:')\n",
    "            for idx in sorted_indices:\n",
    "                print(f'{feature_names[idx]}: {importance[idx]:.4f}')\n",
    "        \n",
    "        print('-' * 30)\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have your data split into X_train, y_train, X_test, y_test\n",
    "train_and_evaluate_models(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson GLM Model:\n",
      "Training R²: 0.2451\n",
      "Training MSE: 1.1584\n",
      "Testing R²: 0.2455\n",
      "Testing MSE: 1.1570\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_and_evaluate_glm(X_train, y_train, X_test, y_test):\n",
    "    # Adding a constant term for the intercept\n",
    "    X_train_const = sm.add_constant(X_train)\n",
    "    X_test_const = sm.add_constant(X_test)\n",
    "    \n",
    "    # Fit the Poisson regression model\n",
    "    poisson_model = sm.GLM(y_train, X_train_const, family=sm.families.Poisson()).fit()\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = poisson_model.predict(X_train_const)\n",
    "    y_test_pred = poisson_model.predict(X_test_const)\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print('Poisson GLM Model:')\n",
    "    print(f'Training R²: {train_r2:.4f}')\n",
    "    print(f'Training MSE: {train_mse:.4f}')\n",
    "    print(f'Testing R²: {test_r2:.4f}')\n",
    "    print(f'Testing MSE: {test_mse:.4f}')\n",
    "    print('-' * 30)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have your data split into train and test sets\n",
    "# X_train, X_test, y_train, y_test\n",
    "\n",
    "# Call the function with your data\n",
    "train_and_evaluate_glm(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions on training and testing data\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return r2, mse, rmse\n",
    "\n",
    "train_r2, train_mse, train_rmse = calculate_metrics(y_train, y_train_pred)\n",
    "test_r2, test_mse, test_rmse = calculate_metrics(y_test, y_test_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Training Metrics: R2: {train_r2:.4f}, MSE: {train_mse:.4f}, RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Testing Metrics: R2: {test_r2:.4f}, MSE: {test_mse:.4f}, RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Model Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = pd.DataFrame({'Feature': X_train.columns, 'Importance': best_model.feature_importances_})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "print(\"Sorted Feature Importances:\\n\", feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df1.iloc[:,np.r_[5,6,7,8,9,10]]\n",
    "y = df1['log_total_apply_starts']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {color: black;background-color: white;}#sk-container-id-31 pre{padding: 0;}#sk-container-id-31 div.sk-toggleable {background-color: white;}#sk-container-id-31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-31 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-31 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-31 div.sk-item {position: relative;z-index: 1;}#sk-container-id-31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-31 div.sk-item::before, #sk-container-id-31 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-31 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-31 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-31 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-31 div.sk-label-container {text-align: center;}#sk-container-id-31 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-31 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(alpha=0.1, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" checked><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(alpha=0.1, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(alpha=0.1, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the XGBoost regressor model\n",
    "xgb_regressor = xgb.XGBRegressor(max_depth = 10, random_state = 1028, n_estimators = 100, alpha = 0.1, eval_metric='rmse', objective='reg:squarederror', )\n",
    "\n",
    "# # Fit the model on the training data\n",
    "xgb_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = xgb_regressor.predict(X_train)\n",
    "y_test_pred = xgb_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate metrics\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics: R2: 0.5441, MSE: 0.6997, RMSE: 0.8365\n",
      "Testing Metrics: R2: 0.5082, MSE: 0.7541, RMSE: 0.8684\n",
      "------------------------------\n",
      "                  Feature  Importance\n",
      "4    advertiser_name_freq    0.544168\n",
      "0              job_salary    0.150411\n",
      "1                 cluster    0.121508\n",
      "5  employee_count_encoded    0.081857\n",
      "2          job_state_freq    0.060012\n",
      "3           job_city_freq    0.042044\n"
     ]
    }
   ],
   "source": [
    "# # Print metrics\n",
    "print(f\"Training Metrics: R2: {train_r2:.4f}, MSE: {train_mse:.4f}, RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Testing Metrics: R2: {test_r2:.4f}, MSE: {test_mse:.4f}, RMSE: {test_rmse:.4f}\")\n",
    "print('-' * 30)\n",
    "\n",
    "feature_importance = pd.DataFrame({'Feature': X_train.columns, 'Importance': xgb_regressor.feature_importances_})\n",
    "sorted_feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "print(sorted_feature_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
